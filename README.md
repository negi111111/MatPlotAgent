## ğŸ“š ç›®æ¬¡ (Table of Contents)

-   [ğŸ“ æœ€è¿‘ã®æ›´æ–°ã‚µãƒãƒª](#-æœ€è¿‘ã®æ›´æ–°ã‚µãƒãƒª-æ—¥æœ¬èª)
-   [ğŸ›  æœ€è¿‘ã®æŠ€è¡“çš„å¤‰æ›´ç‚¹](#-æœ€è¿‘ã®æŠ€è¡“çš„å¤‰æ›´ç‚¹-ç ”ç©¶ç”¨é€”å‘ã‘)
-   [ğŸ§ª å®Ÿé¨“ãƒ—ãƒ­ãƒˆã‚³ãƒ«](#-å®Ÿé¨“ãƒ—ãƒ­ãƒˆã‚³ãƒ«æ¨å¥¨ãƒ•ãƒ­ãƒ¼)
    -   [ç’°å¢ƒæ§‹ç¯‰](#1-ç’°å¢ƒæ§‹ç¯‰)
    -   [ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æŒ‡ç¤ºã‚»ãƒƒãƒˆ](#2-ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æŒ‡ç¤ºã‚»ãƒƒãƒˆ)
    -   [å˜ä¸€ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ](#3-å˜ä¸€ãƒ¢ãƒ‡ãƒ«å˜ä¸€ä¾‹)
    -   [è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ](#4-è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ‘ãƒãƒ«)
    -   [è‡ªå‹•è©•ä¾¡](#5-è‡ªå‹•è©•ä¾¡ä»»æ„)
    -   [æ•´åˆæ€§ / å¤±æ•—æ™‚æŒ™å‹•](#6-æ•´åˆæ€§--å¤±æ•—æ™‚æŒ™å‹•)
    -   [æ¨å¥¨å®Ÿè¡Œé †](#7-æ¨å¥¨å®Ÿè¡Œé †)
    -   [å†ç¾æ€§ãƒ¡ãƒ¢](#8-å†ç¾æ€§ãƒ¡ãƒ¢)
    -   [ãƒ¢ãƒ‡ãƒ«è¿½åŠ æ‰‹é †](#9-ãƒ¢ãƒ‡ãƒ«è¿½åŠ æ‰‹é †)
    -   [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#10-ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ—©è¦‹è¡¨)
-   [`simple_instruction` ã¨ `expert_instruction`](#-simple_instruction-ã¨-expert_instruction-ã®é•ã„)
-   [ä»Šå¾Œã®æ‹¡å¼µäºˆå®š](#-ä»Šå¾Œè¿½åŠ ã‚’æ¤œè¨ã—ã¦ã„ã‚‹æ‹¡å¼µ)
-   [ï¿½ Introduction](#-introduction)
-   [ğŸ‰ News](#-news)
-   [âœ¨ MatPlotAgent](#-matplotagent)
-   [ğŸ– MatPlotBench](#-matplotbench)
-   [âš¡ï¸ Getting Started](#ï¸-getting-started)
-   [Evaluation Pipeline](#evaluation-pipeline)
-   [ğŸ“Š Experiment Results](#-experiment-results)
-   [ğŸ“ˆ Ablation and Case Study](#-ablation-and-case-study)
-   [ğŸ” Citation](#-citation)

---

## ğŸ“ æœ€è¿‘ã®æ›´æ–°ã‚µãƒãƒª (æ—¥æœ¬èª)

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã§ã¯ã€å®Ÿé¨“å†ç¾æ€§ã¨ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã®å³å¯†æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã€ä»¥ä¸‹ã®ä¸»ãªæ”¹å–„ã‚’è¡Œã„ã¾ã—ãŸã€‚å·®åˆ†ã ã‘ã‚’ã“ã“ã«è¦ç´„ã—ã¦ã„ã¾ã™ã€‚

### ã‚³ã‚¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ / API å‘¨ã‚Š

-   Azure AI Inference / Azure OpenAI / Public OpenAI ã‚’ç’°å¢ƒå¤‰æ•°ã ã‘ã§è‡ªå‹•åˆ¤åˆ¥ã™ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ•ã‚¡ã‚¯ãƒˆãƒªã‚’å°å…¥
-   æ¨è«–ç³» (o3 / o4 / gptâ€‘5 / DeepSeek R1 / Grok ãªã©) ã¯ Responses API ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã—ã€å¾“æ¥ãƒãƒ£ãƒƒãƒˆ API ã¨ã®æ··åœ¨ã‚’è§£æ¶ˆ
-   ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®è¨±å®¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å·®ç•°ã«å¯¾å¿œï¼ˆ`temperature` ã‚’æ‹’å¦ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã¯è‡ªå‹•çš„ã«é™¤å»ã€`max_completion_tokens` / `max_output_tokens` / `max_tokens` ã‚’é©åˆ‡ã«åˆ‡æ›¿ï¼‰

### å¯è¦–åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ / ç”»åƒç”Ÿæˆ

-   Matplotlib ã®ã¿ã‚’è¨±å¯ï¼šSeaborn / Plotly ç­‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒç”Ÿæˆã‚³ãƒ¼ãƒ‰ã«å«ã¾ã‚Œã‚‹å ´åˆã¯å†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼†ã‚¯ãƒªãƒ¼ãƒ³
-   å¼·åˆ¶çš„ã« headless (`Agg`) + `plt.show()` é™¤å» + `savefig` æŒ¿å…¥ã§ãƒãƒƒãƒå†ç¾æ€§ã‚’ç¢ºä¿
-   ãƒªãƒ•ã‚¡ã‚¤ãƒ³æ®µéšã§ç”»åƒãŒç”Ÿæˆã•ã‚Œãªã‹ã£ãŸå ´åˆã€è‡ªå‹•çš„ã« `novice.png` ã‚’ `novice_final.png` ã¨ã—ã¦è¤‡è£½ã—ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å®‰å®šåŒ–

### å¤±æ•—ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° / ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒªã‚·ãƒ¼

-   ãƒ¢ãƒ‡ãƒ«è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ã‚’å®Œå…¨å»ƒæ­¢ï¼ˆä»¥å‰å­˜åœ¨ã—ãŸç’°å¢ƒå¤‰æ•°ãƒˆã‚°ãƒ«ã‚‚å‰Šé™¤ï¼‰
-   Responses API å‘¼ã³å‡ºã—å¤±æ•—æ™‚ã¯ç©ºæ–‡å­—ã¾ãŸã¯ None ã‚’è¿”ã—ã€ä¸Šæµã§ã‚ªãƒªã‚¸ãƒŠãƒ«æŒ‡ç¤ºã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆåˆ¥ãƒ¢ãƒ‡ãƒ«å·®ã—æ›¿ãˆã¯ã—ãªã„ï¼‰
-   ä¾‹å¤–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚„ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé€£é–ã«æ··å…¥ã—ãªã„ã‚ˆã†ã‚¬ãƒ¼ãƒ‰è¿½åŠ 

### ãƒãƒƒãƒ / æ¯”è¼ƒå®Ÿé¨“æ”¯æ´

-   `compare_models.py` ã« `--exclude_ids` ã¨ `--dry_run` ã‚’è¿½åŠ ã—é•·æ™‚é–“ãƒãƒƒãƒã®éƒ¨åˆ†å†å®Ÿè¡Œã‚’å®¹æ˜“åŒ–
-   æ¯”è¼ƒã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆç”»åƒã¯ 2 è¡Œæ§‹æˆï¼ˆnovice / finalï¼‰ã®ã¿ã«ç°¡ç´ åŒ–ã—ã€ä¸è¦ãªãƒ©ãƒ™ãƒ«ã¨ ground truth è¡Œã‚’å‰Šé™¤

### ãã®ä»–

-   Responses API ã®ã‚¹ã‚­ãƒ¼ãƒå¤‰æ›´ã«è¿½éš (`input_text` / `input_image`) ã— 400 ã‚¨ãƒ©ãƒ¼ã‚’è§£æ¶ˆ
-   `simple_instruction` ã¨ `expert_instruction` ã®æ¦‚å¿µå·®ã‚’ README æœ«å°¾ã«è§£èª¬
-   è¿½åŠ äºˆå®šï¼ˆæœªå®Ÿè£…ï¼‰ï¼šå¤±æ•—ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ç”»åƒã€JSONL ãƒ­ã‚°ã€çµ±è¨ˆé›†è¨ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã‚Œã‚‰ã¯è«–æ–‡ã®å†ç¾å®Ÿé¨“ã‚„ãƒ¢ãƒ‡ãƒ«é–“æ¯”è¼ƒã®ã€Œé€æ˜æ€§ç¢ºä¿ï¼ˆNo Silent Fallbackï¼‰ã€ã‚’æœ€å„ªå…ˆã«ã—ãŸèª¿æ•´ã§ã™ã€‚è©³ç´°ãªè‹±èªã®æŠ€è¡“çš„èª¬æ˜ã¯ä¸‹éƒ¨ â€œRecent Architectural / Behavioral Changesâ€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

## ï¿½ğŸ›  æœ€è¿‘ã®æŠ€è¡“çš„å¤‰æ›´ç‚¹ (ç ”ç©¶ç”¨é€”å‘ã‘)

ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã€Azure é€£æºã€å®Ÿé¨“ã®å³å¯†æ€§å‘ä¸Šã®ãŸã‚ã«è¡Œã£ãŸä¸»ãªå¤‰æ›´ç‚¹ä¸€è¦§ã§ã™ï¼ˆæ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ã®å·®åˆ†æŠŠæ¡ç”¨ï¼‰ã€‚

| é ˜åŸŸ                   | å¤‰æ›´å†…å®¹                                                                                                 | ç‹™ã„ / åŠ¹æœ                    |
| ---------------------- | -------------------------------------------------------------------------------------------------------- | ------------------------------ |
| ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé¸æŠ       | Azure AI Inference â†’ Azure OpenAI â†’ Public OpenAI ã®å„ªå…ˆé †ä½ã§è‡ªå‹•ç”Ÿæˆ                                   | ç’°å¢ƒå¤‰æ•°è¨­å®šã®ã¿ã§åˆ‡æ›¿         |
| Responses API          | o ç³» / gptâ€‘5 ç³»ã‚’ Responses API ã«çµ±ä¸€ã€‚ãã®ä»–ã¯ Chat API                                                | ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨æ©Ÿèƒ½ã®æ•´åˆæ€§   |
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•´å½¢         | reasoning ç³»ã¯ `temperature` è‡ªå‹•é™¤å»ã€‚`max_completion_tokens` / `max_output_tokens` / `max_tokens` åˆ‡æ›¿ | API ãƒªã‚¸ã‚§ã‚¯ãƒˆå›é¿ãƒ»æ±ºå®šæ€§ç¢ºä¿ |
| ãƒˆãƒ¼ã‚¯ãƒ³æŒ‡å®š           | ãƒ¢ãƒ‡ãƒ«ç¨®åˆ¥ã”ã¨ã«é©æ­£ã‚­ãƒ¼ã¸ãƒãƒƒãƒ”ãƒ³ã‚°                                                                     | ä»•æ§˜éµå®ˆ                       |
| ãƒ“ã‚¸ãƒ§ãƒ³å¯¾å¿œ           | é¸æŠãƒ¢ãƒ‡ãƒ«ãŒç”»åƒéå¯¾å¿œãªã‚‰ãƒªãƒ•ã‚¡ã‚¤ãƒ³ã§ãƒ“ã‚¸ãƒ§ãƒ³å¯¾å¿œä»£æ›¿ã¸ï¼ˆé™çš„æ¡ä»¶å†…ï¼‰                                   | ã‚¯ãƒ©ãƒƒã‚·ãƒ¥é˜²æ­¢                 |
| ãƒ—ãƒ­ãƒƒãƒˆåˆ¶ç´„           | Matplotlib é™å®š + ç¦æ­¢ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¤œå‡ºå†ç”Ÿæˆãƒ«ãƒ¼ãƒ—                                                         | ä½™è¨ˆãªä¾å­˜ã¨ã‚¹ã‚¿ã‚¤ãƒ«æºã‚ŒæŠ‘åˆ¶   |
| ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å®Ÿè¡Œ         | `Agg` å¼·åˆ¶ãƒ»`plt.show()` å‰Šé™¤ãƒ»`savefig` ä¿è¨¼                                                            | ãƒãƒƒãƒå®‰å®šåŒ–                   |
| novice_final ç”Ÿæˆä¿è¨¼  | refine å¤±æ•—æ™‚ã« `novice.png` ã‚’ã‚³ãƒ”ãƒ¼                                                                    | å¾Œç¶šå‡¦ç†ã®æ¬ æé˜²æ­¢             |
| æ¯”è¼ƒã‚°ãƒªãƒƒãƒ‰           | 3 è¡Œ (novice/refined/GT) â†’ 2 è¡Œ (novice/final) ã«ç°¡ç´ åŒ–                                                  | è¦–èªæ€§å‘ä¸Šãƒ»å†—é•·æ’é™¤           |
| ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯   | ã‚µã‚¤ãƒ¬ãƒ³ãƒˆè‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å®Œå…¨å‰Šé™¤                                                                   | å®Ÿé¨“ã®é€æ˜æ€§                   |
| ä¾‹å¤–ä¼æ’­åˆ¶å¾¡           | ä¾‹å¤–/ã‚¨ãƒ©ãƒ¼æ–‡å­—åˆ—ãŒæ¬¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ··å…¥ã—ãªã„ã‚¬ãƒ¼ãƒ‰                                                        | æ±šæŸ“é˜²æ­¢                       |
| ãƒãƒƒãƒé™¤å¤–             | `--exclude_ids` / `--dry_run` ã‚’è¿½åŠ                                                                      | å†å®Ÿè¡ŒåŠ¹ç‡æ”¹å–„                 |
| Responses å…¥åŠ›ã‚¹ã‚­ãƒ¼ãƒ | `input_text` / `input_image` ã¸ä¿®æ­£                                                                      | 400 ã‚¨ãƒ©ãƒ¼è§£æ¶ˆ                 |

## ğŸ§ª å®Ÿé¨“ãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼ˆæ¨å¥¨ãƒ•ãƒ­ãƒ¼ï¼‰

### 1. ç’°å¢ƒæ§‹ç¯‰

```bash
pip install -r requirements.txt
```

ãƒ«ãƒ¼ãƒˆç›´ä¸‹ã«ã‚ã‚‹ `.env.example` ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦è‡ªåˆ†ã®ç§˜å¯†æƒ…å ±ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„:

```bash
cp .env.example .env
```

`.env` ã« Azure / OpenAI ç³»èªè¨¼æƒ…å ±ã‚’è¨­å®šã—ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ°é”æ€§ã‚’ç¢ºèªã—ã¾ã™ã€‚`/Users/<ã‚ãªãŸã®ãƒ¦ãƒ¼ã‚¶å>/...` ã®ã‚ˆã†ãªçµ¶å¯¾ãƒ‘ã‚¹ã¯ **å…±æœ‰ç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¯è¨˜è¼‰ã›ãš**ã€ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®æ±ç”¨è¡¨ç¾ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

| ãƒ­ãƒ¼ã‚«ãƒ«å›ºæœ‰è¨˜è¿°ä¾‹ | æ¨å¥¨ã™ã‚‹æ±ç”¨åŒ–è¡¨ç¾ | å‚™è€ƒ |
| ------------------ | ------------------ | ---- |
| `/Users/yourname/projects/MatPlotAgent` | `$(pwd)` ã¾ãŸã¯ `<project-root>` | ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‚ç…§ |
| `/Users/yourname/.pyenv/versions/...` | `$HOME/.pyenv/versions/...` | ãƒ¦ãƒ¼ã‚¶åç§˜åŒ¿ |
| çµæœå‡ºåŠ›å…ˆ: `/Users/yourname/tmp/runs` | `./runs` | ç›¸å¯¾ãƒ‘ã‚¹ã§å†ç¾æ€§å‘ä¸Š |

> NOTE: ãƒ­ã‚°å‡ºåŠ›ç­‰ã«å®Ÿè¡Œç’°å¢ƒã®ãƒ•ãƒ«ãƒ‘ã‚¹ãŒåŸ‹ã‚è¾¼ã¾ã‚Œã‚‹å ´åˆã€å…¬é–‹å‰ã«ãƒ‘ã‚¹åã«å€‹äººåã‚„ç¤¾åãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚

### 2. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æŒ‡ç¤ºã‚»ãƒƒãƒˆ

`benchmark_data/benchmark_instructions.json` ã«ã¯ 100 ä»¶ã®ã‚±ãƒ¼ã‚¹ãŒã‚ã‚Šã€å„ã‚±ãƒ¼ã‚¹ã¯ `simple_instruction`ï¼ˆç°¡æ½”ãƒ»æ›–æ˜§ï¼‰ã¨ `expert_instruction`ï¼ˆå·¥ç¨‹åˆ—æŒ™ãƒ»æ±ºå®šçš„ï¼‰ã‚’ä¿æŒã—ã¾ã™ã€‚ç¾è¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¯ä¸»ã« simple ã‚’ novice ç”Ÿæˆã«åˆ©ç”¨ã—ã€å¿…è¦ã«å¿œã˜ expert ã‚’è£œåŠ©ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚

### 3. å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒ»å˜ä¸€ä¾‹

```bash
python workflow.py --only_id 10 --model_type o4-mini --workspace ./runs/o4m_ex10
```

æˆæœç‰©: `novice.png`, `novice_final.png`, ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã€`workflow.log`ã€‚

### 4. è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ‘ãƒãƒ«

```bash
python compare_models.py \
  --example_id 10 \
  --workspace ./compare_workspace
```

å‡ºåŠ›: `compare_workspace/example_10_compare.png`ï¼ˆè¡Œ: novice / final Ã— åˆ—: å„ãƒ¢ãƒ‡ãƒ«ï¼‰ã€‚

ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚’ä¸Šæ›¸ã:

```bash
python compare_models.py --example_id 10 \
  --models gpt-5 o3-pro o4-mini grok-3 DeepSeek-R1-0528 \
  --workspace ./compare_workspace
```

å¤šæ•°ä¾‹ + ä¸€éƒ¨é™¤å¤–:

```bash
python compare_models.py --exclude_ids 1 10 16 17 66 77 82 94 96 98 \
  --workspace ./compare_workspace
```

å¯¾è±¡ä¸€è¦§ã®ã¿ç¢ºèª (dry run):

```bash
python compare_models.py --dry_run --workspace ./compare_workspace
```

### 5. è‡ªå‹•è©•ä¾¡ï¼ˆä»»æ„ï¼‰

ç”Ÿæˆå¾Œã«è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã‚¹ã‚³ã‚¢ç®—å‡ºã€‚`novice_final.png` ã¯å¸¸ã«å­˜åœ¨ã™ã‚‹è¨­è¨ˆã€‚

### 6. æ•´åˆæ€§ / å¤±æ•—æ™‚æŒ™å‹•

| ã‚·ãƒŠãƒªã‚ª                                 | ç¾åœ¨ã®æŒ™å‹•                                                          |
| ---------------------------------------- | ------------------------------------------------------------------- |
| reasoning ãƒ¢ãƒ‡ãƒ«ã‚’èª¤ã£ã¦ Chat API ã§å‘¼ã¶ | ã‚¨ãƒ©ãƒ¼ã§å¤±æ•—ã€‚åˆ¥ãƒ¢ãƒ‡ãƒ«ä»£æ›¿ãªã—                                      |
| Responses 400 (ã‚¹ã‚­ãƒ¼ãƒ/Operation)       | ç©ºæ–‡å­—æˆ»ã‚Š â†’ ä¸ŠæµãŒã‚ªãƒªã‚¸ãƒŠãƒ«æŒ‡ç¤ºã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆä»£æ›¿ãƒ¢ãƒ‡ãƒ«ãªã—ï¼‰ |
| refined ç”»åƒæ¬ æ                         | `novice.png` ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦è£œå¡«                                       |
| ç¦æ­¢ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¤œå‡º                       | å†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‹å†ç”Ÿæˆãƒ«ãƒ¼ãƒ—                                          |

### 7. æ¨å¥¨å®Ÿè¡Œé †

1. ã‚¹ãƒ¢ãƒ¼ã‚¯ (1â€“2 ID, 1 ãƒ¢ãƒ‡ãƒ«)
2. å°‘æ•°ã‚µãƒ–ã‚»ãƒƒãƒˆ (5â€“10 ID) ã§æŒ™å‹•/é †ä½ç¢ºèª
3. å…¨ä½“ 100 ID ãƒãƒƒãƒï¼ˆå¿…è¦ãªã‚‰ `--exclude_ids` ã§å†å®Ÿè¡ŒçŸ­ç¸®ï¼‰
4. noviceâ†’final ã®æ”¹å–„é‡ã‚’çµ±è¨ˆé›†è¨ˆ

### 8. å†ç¾æ€§ãƒ¡ãƒ¢

- ä¹±æ•°: æŒ‡ç¤ºã«ã‚ˆã£ã¦ã¯ seed æŒ‡å®šã‚’ä¿ƒã—å®‰å®šæ€§ç¢ºä¿
- Temperature: ã‚°ãƒ­ãƒ¼ãƒãƒ« 0ï¼ˆéå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã¯é€ä¿¡è‡ªä½“ã‚’é™¤å¤–ï¼‰
- ã‚µã‚¤ãƒ¬ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç¦æ­¢: å¤±æ•—ã¯å¤±æ•—ã¨ã—ã¦å¯è¦–åŒ–ï¼ˆç©ºç™½ã‚¿ã‚¤ãƒ«ç­‰ï¼‰
- ç”»åƒã‚µã‚¤ã‚º/é…ç½®ä¸€å®š: ãƒ¢ã‚¶ã‚¤ã‚¯ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå®‰å®š

### 9. ãƒ¢ãƒ‡ãƒ«è¿½åŠ æ‰‹é †

1. OpenAI äº’æ›ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãªã‚‰ `models/model_config.py` ã«è¿½è¨˜
2. Responses API å¿…è¦æ€§ã‚’ç¢ºèªï¼ˆå¿…è¦ãªã‚‰ wrapper å´ã§è‡ªå‹•åˆ¤å®šã•ã‚Œã‚‹ç¯„å›²ã«å‘½åï¼‰
3. å¤§è¦æ¨¡æ¯”è¼ƒã«å«ã‚ãŸã„å ´åˆã¯ `compare_models.py` ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€™è£œã¸è¿½åŠ 

### 10. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ—©è¦‹è¡¨

| ç—‡çŠ¶                                         | åŸå› å€™è£œ                          | å¯¾å‡¦                                              |
| -------------------------------------------- | --------------------------------- | ------------------------------------------------- |
| 400 invalid_value `input_text`/`input_image` | SDK / ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¸æ•´åˆ            | å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»å†èµ·å‹•                            |
| ã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆå†…ãŒç©ºç™½ã‚¿ã‚¤ãƒ«                   | ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ç©º/å®Ÿè¡Œå¤±æ•—             | `<workspace>/<model>/example_X/workflow.log` ç¢ºèª |
| `novice_final.png` ãŒéå»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§æ¬ æ    | refine é€”ä¸­ä¸­æ–­                   | æœ€æ–°ç‰ˆã§è‡ªå‹•è£œå¡«å‹•ä½œã‚’åˆ©ç”¨                        |
| ç¦æ­¢ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæ®‹ã‚‹                         | æ¤œå‡ºæ­£è¦è¡¨ç¾ãŒãƒãƒƒãƒã›ãš          | ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å†ç¢ºèªï¼ˆimport è¡Œä¿®æ­£ï¼‰                 |
| OperationNotSupported (o3-pro)               | ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ/ãƒ‡ãƒ—ãƒ­ã‚¤è¨­å®šä¸æ•´åˆ | Azure Inference å´è¨­å®šç¢ºèª                        |

## ğŸ”¬ `simple_instruction` ã¨ `expert_instruction` ã®é•ã„

`simple_instruction` ã¯ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã§æ›–æ˜§ã•ã‚’å«ã‚€ç›®æ¨™ã€`expert_instruction` ã¯æ‰‹é †ã‚’æ®µéšåˆ—æŒ™ã—ãŸæ±ºå®šçš„ã‚´ãƒ¼ãƒ«è¨˜è¿°ã§ã™ã€‚ä¸¡è€…ã‚’ä½¿ã„åˆ†ã‘ã‚‹ã“ã¨ã§å‰µé€ æ€§è¦æ±‚ã¨æŒ‡ç¤ºå¿ å®Ÿåº¦ã®å·®åˆ†è©•ä¾¡ãŒå¯èƒ½ã§ã™ã€‚ç¾çŠ¶ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¯ä¸»ã« simple ã‚’ novice ç”Ÿæˆã«ç”¨ã„ã€å°†æ¥çš„ãªå¿ å®Ÿåº¦æ¤œè¨¼ã®ãŸã‚ expert ã‚’ä¿æŒã—ã¦ã„ã¾ã™ã€‚

## ğŸ”® ä»Šå¾Œè¿½åŠ ã‚’æ¤œè¨ã—ã¦ã„ã‚‹æ‹¡å¼µ

- å¤±æ•—æ™‚ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ PNGï¼ˆãƒ¢ãƒ‡ãƒ«åï¼‹ã‚¨ãƒ©ãƒ¼çŸ­ç¸®è¡¨ç¤ºï¼‰
- å®Ÿè¡Œãƒ­ã‚° JSONL (`model, example_id, phase, status, error`)
- åŒä¸€å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³é€£ç¶šæ™‚ã®æ—©æœŸæ‰“ã¡åˆ‡ã‚Šãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯
-   æ”¹å–„é‡é›†è¨ˆã¨æˆåŠŸç‡ã‚’ä¸€æ‹¬ç®—å‡ºã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

---

æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªã‚’çµ±åˆã™ã‚‹éš›ã¯ã€Responses / Chat API ã®å¯¾å¿œé–¢ä¿‚ã¨ã€Œã‚µã‚¤ãƒ¬ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç¦æ­¢ã€æ–¹é‡ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚é€æ˜æ€§ä¿æŒãŒæ¯”è¼ƒå®Ÿé¨“ã®ä¿¡é ¼æ€§ã«ç›´çµã—ã¾ã™ã€‚

# ğŸ“– Introduction

Scientific data visualization is crucial for conveying complex information in research, aiding in the identification of implicit patterns. Despite the potential, the use of Large Language Models (LLMs) for this purpose remains underexplored. **MatPlotAgent** introduces an innovative, model-agnostic LLM agent framework designed to automate scientific data visualization tasks, harnessing the power of both code LLMs and multi-modal LLMs.

Integrating LLMs into scientific data visualization represents a new frontier in technology that supports research. Existing tools, such as Matplotlib and Origin, are challenging for many people and learning these tools is time-consuming. **MatPlotAgent** is conceived to bridge this gap, leveraging LLM capabilities to enhance human efficiency significantly. **MatPlotBench** is curated to further traction the field of AI-automated scientific data visualization by providing a comprehensive benchmark and trustworthy automatic evaluation method.

# ğŸ‰ News

- March 7, 2024: Releasing the MatPlotAgent, an innovative and model-agnostic framework designed to revolutionize scientific data visualization by automating tasks with advanced LLMs. ğŸŠ
- March 7, 2024: Releasing MatPlotBench, a comprehensive and meticulously curated benchmark that sets a new standard for evaluating AI-driven visualization tools. ğŸŒŸ

# âœ¨ MatPlotAgent

1. **Query Expansion**: Thoroughly interprets user requirements and transform them into LLM-friendly instructions
2. **Code Generation with Iterative Debugging**: Uses code to preprocess data and generate figures, with self-debugging capabilities.
3. **Visual Feedback Mechanism**: Employs visual perceptual abilities for error identification and correction.
4. **Generalizability**: Demonstrated effectiveness with various LLMs, including commercial and open-source models.

<div align="center">
  <img src="assets/workflow.png" alt="matplotagent framework">
</div>

# ğŸ– MatPlotBench

A high-quality benchmark of 100 human-verified test cases alongside a scoring approach utilizing GPT-4V for automatic evaluation, demonstrating strong correlation with human-annotated scores.

<div align="center">
  <img src="assets/example.png" alt="some examples of MatPlotBench">
</div>

# âš¡ï¸ Getting Started

This project opensources the following components to foster further research and development in the field of scientific data visualization:

- **Benchmark Data (MatPlotBench)**: A meticulously crafted benchmark to quantitatively evaluate data visualization approaches.
- **Evaluation Pipeline**: Utilizes GPT-4V for automatic evaluation, offering a reliable metric that correlates strongly with human judgment.
- **MatPlotAgent Framework**: The entire codebase for the MatPlotAgent framework is available, encouraging adaptation and improvement by the community.

<!-- #TODO
[Instructions on how to access and use the benchmark data, evaluation pipeline, and the MatPlotAgent framework.] -->

Benchmark Data (MatPlotBench) can be found in the `./benchmark_data` folder.

The code requires some dependencies as specified in requirements.txt. Please follow the relevant libraries to install or run:

```bash
pip install -r requirements.txt
```

## MatPlotAgent Framework

### Configuration

If you're using the open-source model, please download the model to your local machine first and adjust the location of the corresponding model in `models/model_config.py`.

If you're using GPT-3.5 or GPT-4, please update your `API_KEY` in `agents/config/openai.py`.

## Use with Azure (OpenAI / AI Inference)

This repository is now configurable to run with Azure-hosted models without changing code.

1. Put your credentials in `.env` at repo root (python-dotenv is used automatically):

- For Azure OpenAI (deployment-based):

  - `AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/`
  - `AZURE_OPENAI_API_KEY=***`
    -   `AZURE_OPENAI_API_VERSION=2025-04-01-preview` (or your supported version)

-   For Azure AI Inference (serverless, multi-provider models like o3, DeepSeek, Grok, etc.):
    -   `AZURE_INFERENCE_ENDPOINT=https://<your-endpoint>/openai/deployments/<deployment>/extensions`
    -   `AZURE_INFERENCE_API_KEY=***`

The code auto-detects in this order:

1. `AZURE_INFERENCE_*` (AI Inference)
2. `AZURE_OPENAI_*` (Azure OpenAI)
3. `OPENAI_API_KEY` + optional `OPENAI_BASE_URL` (api.openai.com)

4. Model names

-   For Azure OpenAI, pass the deployment name as `model_type` (e.g., `--model_type o4-mini` if your deployment is named `o4-mini`).
-   For Azure AI Inference, pass the model id. Confirm the model is enabled on your endpoint. Verified families include:
    -   OpenAI: `gpt-5`, `gpt-5-mini`, `gpt-5-nano`, `gpt-4o`, `gpt-4o-mini`
    -   o-series: `o3`, `o3-mini`, `o3-pro`, `o4-mini`
    -   DeepSeek: `DeepSeek-R1-0528`
    -   Grok: `grok-3`, `grok-3-mini`

3. Vision models

-   By default, evaluation uses `EVAL_TEXT_MODEL=gpt-4` and `EVAL_VISION_MODEL=gpt-4-vision-preview`.
-   Override via `.env` if needed, e.g., `EVAL_TEXT_MODEL=o3`, `EVAL_VISION_MODEL=gpt-4o`.

No code changes are required once `.env` is configured; the client is created dynamically.

Notes:

-   Some reasoning models (o-series, DeepSeek R1, Grok) do not accept `temperature`. The framework automatically omits it for those models and uses the right token parameter (`max_completion_tokens` for o-series).

### Running OpenAI-Compatible Server

If you're utilizing GPT-3.5 or GPT-4, you can skip this section.

We use vLLM to deploy the open-source model as a server, implementing the OpenAI API protocol. This enables vLLM to seamlessly replace applications using the OpenAI API.

Ensure you have vLLM installed and configured on your local machine.

We provide scripts to deploy the API server. For instance, to deploy `CodeLlama-34b-Instruct`, you can execute:

```
bash models/scripts/CodeLlama-34b-Instruct-hf.sh
```

If you need to modify the script's content, please refer to the [vLLM documentation](https://docs.vllm.ai/en/latest/index.html).

### Running MatPlotAgent Framework

To execute the MatPlotAgent framework, use the following script:

```bash
python workflow.py \
    --model_type=MODEL \
    --workspace=path/to/result
```

Replace `MODEL` with the desired model. All available `model_type` options can be found in `models/model_config.py`.

Replace `path/to/result` with the desired path to save the results.

For direct decoding, use:

```bash
python one_time_generate.py \
  --model_type=MODEL \
  --workspace=path/to/result
```

For chain-of-thought variant:

```bash
python one_time_generate_COT.py \
  --model_type=MODEL \
  --workspace=path/to/result
```

## Evaluation Pipeline

After running the MatPlotAgent Framework, you can utilize the Evaluation Pipeline to obtain automatic evaluation scores.

First, replace `directory_path` with `path/to/result` in `evaluation/api_eval.py` and `evaluation/average_score_calc.py`.

Run the evaluation shell script:

```bash
bash evaluation/eval.sh
```

Then (if needed) change into the evaluation directory for manual scripts:

```bash
cd evaluation
```

# ğŸ“Š Experiment Results

Our experiments showcase MatPlotAgent's ability to improve LLM performance across a variety of aspects, with notable enhancements in plot quality and correctness, supported by both quantitative scores and qualitative assessments.

Performance of different LLMs on MatPlotBench. For each model, improvements over the direct decoding are highlighted in **bold**.

| Model                                                                              | Direct Decod. | Zero-Shot CoT     | MatPlotAgent w/ GPT-4V |
| ---------------------------------------------------------------------------------- | ------------- | ----------------- | ---------------------- |
| **GPT-4**                                                                          | 48.86         | 45.42 (-3.44)     | 61.16 (**+12.30**)     |
| **GPT-3.5**                                                                        | 38.03         | 37.14 (-0.89)     | 47.51 (**+9.48**)      |
| **Magicoder-S-DS-6.7B** ([Wei et al.,](https://arxiv.org/abs/2312.02120))          | 38.49         | 37.95 (-0.54)     | 51.70 (**+13.21**)     |
| **Deepseek-coder-6.7B-instruct** ([Guo et al.,](https://arxiv.org/abs/2401.14196)) | 31.53         | 29.16 (-2.37)     | 39.45 (**+7.92**)      |
| **CodeLlama-34B-Instruct** ([RoziÃ¨re et al.,](https://arxiv.org/abs/2308.12950))   | 16.54         | 12.40 (-4.14)     | 14.18 (-2.36)          |
| **Deepseek-coder-33B-instruct** ([Guo et al.,](https://arxiv.org/abs/2401.14196))  | 30.88         | 36.10 (**+5.22**) | 32.18 (**+1.30**)      |
| **WizardCoder-Python-33B-V1.1** ([Luo et al.,](https://arxiv.org/abs/2306.08568))  | 36.94         | 35.81 (-1.13)     | 45.96 (**+9.02**)      |

Additionally, we present the results of using Gemini Pro Vision as the visual agent on GPT-4 and GPT-3.5, showcasing a considerable improvement of 7.87 and 5.45, respectively, over the direct decoding baseline. This evidence further demonstrates our method's model-agnostic characteristics by using various multimodal LLMs to achieve improved performance.

| Model   | Direct Decod. | MatPlotAgent w/ Gemini Pro Vision |
| ------- | ------------- | --------------------------------- |
| GPT-4   | 48.86         | 56.73 (**+7.87**)                 |
| GPT-3.5 | 38.03         | 43.48 (**+5.45**)                 |

We assessed MatPlotAgent's performance on the visualization subset of the Code Interpreter Benchmark, which was released alongside Qwen-agent, witnessing notable improvements over GPT-4. These results underscore the efficacy of our approach in enhancing visualization capabilities.

<table>
  <thead>
    <tr>
      <th rowspan="2"><strong>Model</strong></th>
      <th colspan="3" align="center"><strong>Accuracy of Code Execution Results (%)</strong></th>
    </tr>
    <tr>
      <th align="center"><strong>Visualization-Hard</strong></th>
      <th align="center"><strong>Visualization-Easy</strong></th>
      <th align="center"><strong>Average</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>GPT-4</td>
      <td align="center">66.7</td>
      <td align="center">60.8</td>
      <td align="center">63.8</td>
    </tr>
    <tr>
      <td><strong>+ MatPlotAgent</strong></td>
      <td align="center"><strong>72.6</strong></td>
      <td align="center"><strong>68.4</strong></td>
      <td align="center"><strong>70.5</strong></td>
    </tr>
    <tr>
       <td><em>w/o Visual Feedback</em></td>
      <td align="center">66.7</td>
      <td align="center">65.8</td>
      <td align="center">66.3</td>
    </tr>
  </tbody>
</table>

## ğŸ“ˆ Ablation and Case Study

Examples to illustrate the effect of visual feedback. To investigate the effect of the visual feedback mechanism on different models, we display the outputs of two representative LLMs. Case A, B, and C are generated by GPT-4. Case D is generated by Magicoder-S-DS-6.7B.

<div align="center">
  <img src="assets/ablation.png" alt="Examples to illustrate the effect of visual feedback. To investigate the effect of the visual feedback mechanism on different models, we display the outputs of two representative LLMs. Case A, B, and C are generated by GPT-4. Case D is generated by Magicoder-S-DS-6.7B.">
</div>

Case study of different models

<div align="center">
  <img src="assets/case.png" alt="Case study of different models">
</div>

# ğŸ” Citation

Feel free to cite the paper if you think MatPlotAgent is useful.

```bibtex
@misc{yang2024matplotagent,
      title={MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization},
      author={Zhiyu Yang and Zihan Zhou and Shuo Wang and Xin Cong and Xu Han and Yukun Yan and Zhenghao Liu and Zhixing Tan and Pengyuan Liu and Dong Yu and Zhiyuan Liu and Xiaodong Shi and Maosong Sun},
      year={2024},
      eprint={2402.11453},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

---
